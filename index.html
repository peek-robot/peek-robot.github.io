<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="description"
content="PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies">
<meta name="keywords" content="Robot Learning, Imitation Learning, VLAs, Zero-Shot Generalization, Robot Manipulation">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies</title>

<link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
rel="stylesheet">

<link rel="stylesheet" href="./static/css/bulma.min.css">
<link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
<link rel="stylesheet" href="./static/css/bulma-slider.min.css">
<link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
<link rel="stylesheet"
href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
<link rel="stylesheet" href="./static/css/index.css">
<link rel="icon" href="./static/images/peek_emoji.png">

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script defer src="./static/js/fontawesome.all.min.js"></script>
<script src="./static/js/bulma-carousel.min.js"></script>
<script src="./static/js/bulma-slider.min.js"></script>
<script src="./static/js/index.js"></script>
  <!-- Include MathJax -->
<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
  <script type="text/javascript">
    // Ensure MathJax is fully loaded before configuring it
    window.onload = function() {
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$', '$']]  // This ensures inline math works with $
        }
      });

      // Optionally, reprocess math formulas on page load
      MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
    };
  </script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
            <h1 class="title is-1 publication-title" style="font-size:2.8rem;">
            <img src="./static/images/peek_emoji.png" alt="ReWiND Logo" style="height:1em; vertical-align:middle; margin-right:0.2em;">
            PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies</h1>
	  <!--<h3 class="title is-4 conference-authors"><a target="_blank" href="https://iclr.cc/">ICLR 2025</a></h3>-->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://jessezhang.net/">Jesse Zhang</a><sup>*1,2,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://memmelma.github.io/">Marius Memmel</a><sup>*1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://minjunkevink.github.io/">Kevin Kim</a><sup>3</sup>,
            </span>
            <br>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~fox/">Dieter Fox</a><sup>1,4</sup>,
            </span>
            <span class="author-block">
              <a href="https://jessethomason.com/">Jesse Thomason</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://fabioramos.github.io/Home.html">Fabio Ramos</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://ebiyik.github.io/">Erdem Bıyık</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~abhgupta/">Abhishek Gupta</a><sup>†1</sup>,
            </span>
            <span class="author-block">
              <a href="https://anqili.github.io/">Anqi Li</a><sup>†2</sup>,
            </span>
          </div>


          <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University of Washington,</span>
              <span class="author-block"><sup>2</sup>NVIDIA,</span>
              <span class="author-block"><sup>3</sup>University of Southern California,</span>
              <span class="author-block"><sup>4</sup>Allen Institute for AI</span>
          </div>
          <br> 
          <div class="is-size-7 publication-authors">
              <span class="author-block"><sup>*</sup>Co-first Author</span>
              <span class="author-block"><sup>†</sup>Equal Advising</span>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- ArXiv -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2502.05485" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv (todo)</span>
                </a>
              </span>
              <!-- Demo Link. -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/peek-robot/peek"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (in progress)</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>


  <div class="container is-max-desktop">

    <section class="section">
      <div class="container is-max-desktop">
        <div class="is-centered has-text-centered">
          <video id="teaser_video" width=100% muted controls style="border-radius:10px;" margin="auto">
            <source src="static/videos/PEEK_video_small.mp4">
          </video>
        </div>
      </div>
    </section>




    <!--/ Paper video. -->
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Summary</h2>
	<p>
	    <figure>
	    <img src="./static/images/peek_teaser.jpg" style="width: 75%; height: auto;">
	    </figure>
        <div class="content has-text-justified">
          <br>
	  <b>PEEK</b> enhances the zero-shot generalization ability of any RGB-input manipulation policy by showing policies
    <i>where to focus on</i> and <i>what to do</i>. This guidance is 
    given to the policy via a VLM that predicts <i>paths</i> and <i>masking points</i> to 
    draw onto the policy's input images in closed-loop.
    This allows policies to focus on just <i>how</i> to execute low-level actions.
	  <br>


	  <!--<b>Motivation:</b> Large models have shown strong open-world generalization to complex problems in vision and language, but they have been relatively more difficult to deploy in robotics. This challenge stems from several factors, the foremost of which is the lack of scalable robotic training data since this requires expensive on-robot collection.
	  <br>
	  <b>Highlights:</b> We study a class of hierarchical VLA models, where high-level VLMs are trained on relatively cheap data to produce semantically meaningful intermediate predictions such as 2D paths indicating desired behavior. These predicted 2D paths can serve as guidance for low-level control policies that are 3D-aware and capable of precise manipulation. We show that separating prediction into semantic high-level predictions, and 3D-aware low-level predictions allows such hierarchical VLA policies to transfer across significant domain gaps, for instance from simulation to the real world or across scenes with widely varying visual appearance. Doing so allows for the usage of cheap, abundant data sources beyond teleoperated on-robot data thereby enabling broad semantic and visual generalization.
         </p>
        </div>
      </div>
    </div>
  -->
    <!--/ Abstract. -->
  </div>
  <div class="content has-text-justified">
    <h4 class="title is-5">1. VLM Fine-tuning and Data Preparation</h4>
    <b>Overview:</b>
    <p>
      To help generalization of the policy, the VLM itself needs to be able to generalize well to new tasks.
      We fine-tune a pre-trained VLM on a large, automatically labeled robotics dataset to produce <i>paths</i> and <i>masking points</i>.
      Paths help the policy understand <i>what</i> to do, and masking points help the policy understand <i>where</i> to focus on.
    </p>
    <b>Data Labeling Pipeline:</b>
    <figure>
    <img src="./static/images/peek_data_labeling.jpg">
    </figure>
    <p>
    The data labeling pipeline: (1) Detect task-relevant moving points, (2) mask irrelevant areas and extract gripper paths, (3) segment trajectories, and (4) generate gripper paths and masking points for each segment.
    This scalable labeling pipeline allows to label 20 robotics datasets from Open-X!
    </p> 
    <b>VLM Fine-tuning:</b>
    <p>
      We fine-tune a VILA-1.5-3b on the automatically labeled data to produce <i>paths</i> and <i>masking points</i> conditioned on robot image observations and task instructions.
    </p>
  <h4 class="title is-5">2. Policy Training and Inference</h4>
    <figure>
    <img src="./static/images/peek_policy_training.jpg"></a>
    </figure>
    <p> At training time, we use the VLM to predict paths and masks every $H$ steps in closed loop.
      These paths and masks are drawn onto all images that the policy sees, $o_t^{p,m}$, where it predicts low-level environment actions.
      At inference time, the VLM is used in the same way, constantly predicting updated paths and masks in closed loop during policy execution.
      This process is compatible with any RGB-input policy! 
    </p>
  <hr>
  </div>

</section>

<section class="section">

  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <h2 class="title is-2">Experiments and Results</h2>
    </div>
    <div class="content has-text-centered">
      <img src="static/images/peek franka envs.jpg">
      <img src="static/images/peek bridge envs.jpg">
      <br>
      <b>
        Our Environments and initial PEEK VLM predictions.
      </b>
    </div>
    We perform <b>535 real-world evaluations</b> across 17 task variations and implement PEEK on top of 3 policy architectures.
    <p>(1): <b>Franka Sim-to-Real:</b> We train only in simulation and evaluate zero-shot in real with a 3D policy (3DDA). <br>
      (2): <b>WidowX Bridge:</b> We train on the BRIDGE dataset and evaluate zero-shot on our custom WidowX setup.
    </p>
    <br>
    <div class="content has-text-centered">
      <img src="static/images/peek_results.jpg">
      <br>
    </div>
        PEEK improves performance of 2D (ACT, $\pi_0$) and 3D imitation learning (3DDA) policies in generalization to new task variations.
      We separate results into a variety of sections demonstrating various capabilities of PEEK below:
      <br>
      <br>
    <hr>
  </div>
  <br>

  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <h3 class="title is-3">Extreme Clutter and Policy Reactivity</h3>
    </div>
    <h6 class="title is-6 has-text-centered">3DDA+PEEK, training data: Block Stacking in Simulation</h6>
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
            <source src="static/videos/3dda+peek/8x_small_cube_move_clutter_2x_0.mp4" type="video/mp4" class="figure-img img-fluid rounded">
          </video>
          <p><b>Task: Put the blue cube on the red cube</b></p>
        </div>
      </div>
      <div class="column">
        <div class="content">
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
            <source src="static/videos/3dda+peek/8x_small_cube_move_clutter_2x_1.mp4" type="video/mp4" class="figure-img img-fluid rounded">
          </video>
          <p><b>Task: Put the blue cube on the red cube</b></p>
        </div>
      </div>
    </div>


    <p style="font-size: 10px;">8x speed, pauses come mainly from FoundationStereo depth queries.</p>
    <br>
    <hr>
    <br>
  </div>

  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <h3 class="title is-3">Semantic Generalization</h3>
    </div>

    <br>
    <h6 class="title is-6 has-text-centered">Standard $\pi_0$, training data: BRIDGE</h6>
  <div class="columns is-centered">
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
        <source src="static/videos/pi0/small_give the banana to jensen huang.MOV" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
      <p><b>Task: Give the banana to Jensen Huang (gets stuck)</b></p>
    </div>
  </div>
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
        <source src="static/videos/pi0/small_put green pepper in green drawer.MOV" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
      <p><b>Task: Put the green pepper in the green drawer (wrong drawer)</b></p>
    </div>
  </div>
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay="" controls="" muted="" loop="" playsinline="" height="100%" onloadstart="this.playbackRate=1">
        <source src="static/videos/pi0/small_put the healthy food on the plate.MOV" healthy food on the plate.MOV" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
      <p><b>Task: Put the healthy food on the plate (grabs pizza instead of carrrot)</b></p>
    </div>
  </div>
  </div>

  <h6 class="title is-6 has-text-centered">$\pi_0$+PEEK, training data: BRIDGE</h6>
  <div class="columns is-centered">
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
        <source src="static/videos/pi0+peek/small_give the banana to jensen huang.MOV" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
      <p><b>Task: Give the banana to Jensen Huang</b></p>
    </div>
  </div>
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
        <source src="static/videos/pi0+peek/small_put green pepper in green drawer.MOV" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
      <p><b>Task: Put the green pepper in the green drawer</b></p>
    </div>
  </div>
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay="" controls="" muted="" loop="" playsinline="" height="100%" onloadstart="this.playbackRate=1">
        <source src="static/videos/pi0+peek/small_Put the healthy food on the plate.MOV" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
      <p><b>Task: Put the healthy food on the plate</b></p>
    </div>
  </div>
  </div>

  <!--<div class="columns is-centered">
    <div class="column">
      <div class="content">
        <video id="dollyzoom" autoplay="" controls="" muted="" loop="" playsinline="" height="100%" onloadstart="this.playbackRate=2">
          <source src="figs/ep_2_pick_up_the_energy_bar_and_put_it_in_the_red_bowl.MP4" type="video/mp4" class="figure-img img-fluid rounded">
        </video>
      </div>
    </div>
    <div class="column">
      <div class="content">
        <video id="dollyzoom" autoplay="" controls="" muted="" loop="" playsinline="" height="100%" onloadstart="this.playbackRate=2">
          <source src="figs/ep_3_pick_up_the_smile_face_and_put_it_in_the_red_bowl.MP4" type="video/mp4" class="figure-img img-fluid rounded">
        </video>
      </div>
    </div>
  </div>-->
    <p style="font-size: 10px;">Videos play at dynamic iPhone timelapse speed</p>
    <br>
    <hr>
  <br>
    </div>


  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <h3 class="title is-3">Visual Clutter</h3>
    </div>
    <h6 class="title is-6 has-text-centered">Vanilla ACT, training data: BRIDGE</h6>
  <div class="columns is-centered">
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
        <source src="static/videos/act/small_push the button.MOV" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
      <p><b>Task: Push the button (doesn't know what to do)</b></p>
    </div>
  </div>
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
        <source src="static/videos/act/small_put the carrot in the drawer.MOV" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
      <p><b>Task: Put the carrot in the drawer (goes for drawer)</b></p>
    </div>
  </div>
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay="" controls="" muted="" loop="" playsinline="" height="100%" onloadstart="this.playbackRate=1">
        <source src="static/videos/act/small_slide the pot to the shrimp.MOV" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
      <p><b>Task: Slide the pot to the shrimp (goes for shrimp)</b></p>
    </div>
  </div>
  </div>

    <h6 class="title is-6 has-text-centered">ACT+PEEK, training data: BRIDGE</h6>
  <div class="columns is-centered">
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
        <source src="static/videos/act+peek/small_push the button.MOV" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
      <p><b>Task: Push the button</b></p>
    </div>
  </div>
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
        <source src="static/videos/act+peek/small_put the carrot in the drawer.MOV" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
      <p><b>Task: Put the carrot in the drawer (partial success: missed drop)</b></p>
    </div>
  </div>
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay="" controls="" muted="" loop="" playsinline="" height="100%" onloadstart="this.playbackRate=1">
        <source src="static/videos/act+peek/small_slide the pot to the shrimp.MOV" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
      <p><b>Task: Slide the pot to the shrimp</b></p>
    </div>
  </div>
  </div>

  <p style="font-size: 10px;">Videos play at dynamic iPhone timelapse speed</p>
  <br>
  <hr>
  </div>
  <br>
  
  <!--<div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <h3 class="title is-3">VLM Visual Generalization</h3>
    <br>
    </div>
    <hr>
  </div> -->

  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <h3 class="title is-3">Extreme Object Generalization</h3>
    </div>
    <h6 class="title is-6 has-text-centered">3DDA+PEEK, training data: Putting cans on pans in Simulation</h6>

      <div class="content is-centered has-text-centered">
        <video id="dollyzoom" autoplay controls muted loop playsinline width="100%" onloadstart="this.playbackRate=1">
          <source src="static/videos/3dda+peek/8x_small_flamingo_kobe_2x.mp4" type="video/mp4" class="figure-img img-fluid rounded">
        </video>
        <p><b>Task: Put the flamingo on Kobe Bryant</b></p>

      <br>
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
            <source src="static/videos/3dda+peek/8x_small_drawer_2x_0.mp4" type="video/mp4" class="figure-img img-fluid rounded">
          </video>
          <p><b>Task: Close the drawer</b></p>

          <br>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
            <source src="static/videos/3dda+peek/8x_small_labubu_2x_0.mp4" type="video/mp4" class="figure-img img-fluid rounded">
          </video>
          <p><b>Task: Put the Labubu toy on the oreo box</b></p>
        </div>
      </div>
      <div class="column">
        <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
          <source src="static/videos/3dda+peek/8x_small_spiderman_clutter_2x_0.mp4" type="video/mp4" class="figure-img img-fluid rounded">
        </video>
        <p><b>Task: Put the spiderman in the lunch box</b></p>
          <br>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
            <source src="static/videos/3dda+peek/8x_small_labubu_2x_1_sdr.mp4" type="video/mp4" class="figure-img img-fluid rounded">
          </video>
          <p><b>Task: Put the Labubu toy in the shopping bag</b></p>
        </div>
        <br>
      </div>
    </div>

    <p style="font-size: 10px;">Videos play at 8x speed</p>
    <br>
    <hr>
    <br>
  </div>
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <h3 class="title is-3">What Does the Policy See?</h3>
    <br>
    </div>
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
            <source src="static/videos/policy_vis_stacked_green_pepper.mp4" type="video/mp4" class="figure-img img-fluid rounded">
          </video>
        <p><b>Task: Put the green pepper in the green drawer</b></p>
        </div>
        <div class="content has-text-centered">
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
            <source src="static/videos/policy_vis_cube_1_stacked.mp4" type="video/mp4" class="figure-img img-fluid rounded">
          </video>
        <p><b>Task: Put the blue block on the red block</b></p>
        </div>

      </div>
      <div class="column">
        <div class="content has-text-centered">
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
            <source src="static/videos/policy_vis_stacked_healthy.mp4" type="video/mp4" class="figure-img img-fluid rounded">
          </video>
          <p><b>Task: Put the healthy food on the plate</b></p>
        </div>
        <div class="content has-text-centered">
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
            <source src="static/videos/policy_vis_cube_2_stacked.mp4" type="video/mp4" class="figure-img img-fluid rounded">
          </video>
          <p><b>Task: Put the red block on the blue block</b></p>
        </div>
      </div>
    </div>
  </div>
  <br>
  <hr>
  <br>

  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <h3 class="title is-3">Ablation Study: Paths vs Masks?</h3>
    <br>
    </div>
  </div>

  <div class="container is-max-desktop is-centered">
    <h5 class="title is-6 has-text-centered">
      Ablation of path and mask supervision on success rate in simulation.
    </h5>
    <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
      <thead>
        <tr>
          <th>Paths p</th>
          <th>Masks m</th>
          <th>Success (%)</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>✗</td>
          <td>✗</td>
          <td>33.5 &plusmn; 3.1</td>
        </tr>
        <tr>
          <td>✓</td>
          <td>✗</td>
          <td>52.8 &plusmn; 2.9</td>
        </tr>
        <tr>
          <td>✗</td>
          <td>✓</td>
          <td>65.6 &plusmn; 3.1</td>
        </tr>
        <tr>
          <td>✓</td>
          <td>✓</td>
          <td><b>73.6 &plusmn; 3.9</b></td>
        </tr>
      </tbody>
    </table>
  <br>
        <p>
          PEEK benefits from both paths and masks, with the combination of the two achieving the highest success
          rate on just block stacking, without any generalization challenges, in simulation.
          We can see in the real-world results that masks become even more important in cluttered real-world scenes.
        </p>
    <br>
  </div>
  <!--<h5 class="title is-6">Fine-tuning the VLM on paths automatically generated from human hand data.</h5>
  <div class="columns is-centered">
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%" onloadstart="this.playbackRate=1">
        <source src="figs/hand_tracking_example.mp4" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
    </div>
  </div>
  <p><b>TODO:</b> fill in with an example image of video of block stacking</p>
  <div class="column">
    <div class="content">
      <video id="dollyzoom" autoplay="" controls="" muted="" loop="" playsinline="" height="100%" onloadstart="this.playbackRate=2">
        <source src="figs/TODO" type="video/mp4" class="figure-img img-fluid rounded">
      </video>
    </div>
  </div>
</div> -->

  <hr>
    </div>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@inproceedings{zhang2025peek,
      title={PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies}, 
      author={Jesse Zhang and Marius Memmel and Kevin Kim and Dieter Fox and Jesse Thomason and Fabio Ramos and Erdem Bıyık and Abhishek Gupta and Anqi Li},
      booktitle={arXiv:TODO FILL},
      year={2025},
}
  </code></pre>
    </div>
  </section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Based on the awesome open source template <a
              href="https://github.com/nerfies/nerfies.github.io">from here.</a>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>